#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass book
\begin_preamble


\AtBeginDocument{
  \def\labelitemii{\ding{71}}
  \def\labelitemiii{\ding{111}}
  \def\labelitemiv{\(\vartriangleright\)}
}



\usepackage{babel}
\addto\shorthandsspanish{\spanishdeactivate{~<>}}
\end_preamble
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding iso8859-15
\fontencoding T1
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing double
\use_hyperref true
\pdf_bookmarks false
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref section
\pdf_pdfusetitle false
\papersize a4paper
\use_geometry true
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1.5in
\topmargin 1.6in
\rightmargin 1.2in
\bottommargin 1.6in
\headheight 1.5in
\headsep 0.3in
\footskip 0.8in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle plain
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
State of the Art
\noun on

\begin_inset CommandInset label
LatexCommand label
name "cha:State Of the Art"

\end_inset


\end_layout

\begin_layout Standard
As explained during Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "cha:Introduction"

\end_inset

 the process of analysis of a common crowed space will join many algorithms
 from different Computer Vision disciplines.
 Throughout this Chapter we will summarize the actual and most used algorithms
 in the different categories that we will use during the development of
 the project.
\end_layout

\begin_layout Section
Pedestrian detection and crowd patrons
\begin_inset CommandInset label
LatexCommand label
name "sec:Pedestrian-detection-and crowd patrons"

\end_inset


\end_layout

\begin_layout Subsection
Available Datasets
\end_layout

\begin_layout Standard
Pedestrian detection has been a major issue in computer vision during the
 past few years due to its potential uses for modern applications.
 It keeps being a research area because of the large amount of available
 datasets with different video and people characteristics such as people
 occlusions, poses, scales, illumination ranges...
 Those datasets include among others:
\end_layout

\begin_layout Itemize
Caltech 
\begin_inset CommandInset citation
LatexCommand cite
key "dollar2009pedestrian"

\end_inset

, which consists on video taken from a vehicle diving through regular traffic
 in an urban environment.
\end_layout

\begin_layout Itemize
ETHZ 
\begin_inset CommandInset citation
LatexCommand cite
key "ess2007depth"

\end_inset

.
 It consists on recordings using a pair of AVT Marlins F033C mounted on
 a chariot which moves through pedestrian paths.
\end_layout

\begin_layout Itemize
TUD 
\begin_inset CommandInset citation
LatexCommand cite
key "wojek2009multi"

\end_inset

.
 In this case, the recording has been done by a static camera in a crossing
 campus scene.
\end_layout

\begin_layout Itemize
INRIA 
\begin_inset CommandInset citation
LatexCommand cite
key "dalal2005histograms"

\end_inset

 which collects precise people images both static and moving.
 In this case, images fully represent people without taking into account
 the environment.
\end_layout

\begin_layout Standard
As a result of this large amount of training and testing data, some detectors
 perform better in terms of precision and time consumption than others depending
 on the specific situations.
\end_layout

\begin_layout Subsection
Main Detectors
\end_layout

\begin_layout Standard
Main pedestrian detections that have been used so far can be divided in
 many categories and from many points of views.
 One possible easy classification depending on the used descriptor may start
 with the ones that use Histograms of Oriented Gradients like 
\begin_inset CommandInset citation
LatexCommand cite
key "dalal2005histograms"

\end_inset

 in combination with linear Support Vectors Machine in order to describe
 pedestrian shape with gradients to create a model and classify possible
 candidates.
 Secondly, Discriminative Part Models as 
\begin_inset CommandInset citation
LatexCommand cite
key "felzenszwalb2008discriminatively"

\end_inset

 that will divide the human body into different parts (head, trunk, legs...)
 and search for them into the image for a later combination into a single
 person detection, or finally Aggregate Channel Features 
\begin_inset CommandInset citation
LatexCommand cite
key "dollar2014fast"

\end_inset

 which will use a combination of different channels such as normalized gradient
 magnitude, histogram of oriented gradients (6 channels), and LUV color
 channels in order to achieve the final detection.
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand cite
key "garcia2015people"

\end_inset

 an extensive evaluation of the state of the art of people detection is
 given.
 Here algorithms are characterize and differentiate ones from the others
 depending on the object detection approach and the person model used.
 Object detection will be the extraction of the possible candidates to be
 a person from the scene.
 Main algorithms usually will use:
\end_layout

\begin_layout Itemize
Sliding window: The so called exhaustive search will lead to an efficient
 classifier to test, in search of pedestrian, every possible image window.
 Parameters such as window size, or overlapping are common tuning values
 that will increase or decrease the performance of the detector.
 Those methods usually need from 
\begin_inset Formula $10^{4}$
\end_inset

 to 
\begin_inset Formula $10^{5}$
\end_inset

 windows per image and this number will grow exponentially for multi-scale
 detection.
 If the complexity of the core classifier is increased in every window testing,
 the computational time will end up being not affordable.
\end_layout

\begin_layout Itemize
Segmentation: This approach will introduce some sort of segmentation as
 a preliminary step for the pedestrian detection.
 Algorithms such as background subtraction will lead to some moving parts
 of the image that will generate interest objects from moving patterns.
 Others such as color segmentation are based on color skin to restrict the
 future people search only to those objects that fulfill the color condition.
 By all means, segmentation will directly produce those scene candidates
 to be a person and so the computational time is highly decreased.
\end_layout

\begin_layout Itemize
Segmentation + Exhaustive search: The final approach will be the combination
 of both previously analyzed techniques.
 In this case the previous step of segmentation will not lead to final candidate
s objects but to an area that could contain some candidates objects.
 After segmentation process and sliding window technique is perform over
 the reduce scene area and so the final candidates are extracted.
 In this case improvements from both approaches are used as the computational
 cost of the exhaustive search (that is the main drawback) is reduce by
 the use of some sort of segmentation.
\end_layout

\begin_layout Standard
Moving to person model, or in other words the set of characteristics that
 will be able to discriminate between people and any other object in the
 scene, 
\begin_inset CommandInset citation
LatexCommand cite
key "garcia2015people"

\end_inset

differentiates three different groups:
\end_layout

\begin_layout Itemize
Based on appearance: Most of the available detectors nowadays use appearance
 information to define the person model and so, to discriminate between
 person and the rest of the scene.
 In this group of person model one can differentiate two approaches to describe
 the shape of a person.
\end_layout

\begin_deeper
\begin_layout Itemize
Holistic: With this models people will be defined from the easiest point
 of view when a person is a region or a shape
\end_layout

\begin_layout Itemize
Part-based: These models however, use more complex model where people are
 defined as a combination of multiple shapes or regions from its body.
\end_layout

\begin_layout Standard
Here one can find those that use silhouettes to classify people, either
 from an holistic or part-based point of view, or color distribution in
 people, however the most used approaches as said at the beginning of the
 section, use Histograms of Oriented Gradients like 
\begin_inset CommandInset citation
LatexCommand cite
key "dalal2005histograms"

\end_inset

, Haar-like features 
\begin_inset CommandInset citation
LatexCommand cite
key "alonso2007combination"

\end_inset

, or combination of multiple features, aggregate channel features: HOG,
 gradient and color (ACF) 
\begin_inset CommandInset citation
LatexCommand cite
key "dollar2014fast"

\end_inset

.
\end_layout

\end_deeper
\begin_layout Itemize
Based on motion: As said before many of the detectors usually are based
 on appearance, however, human appearance is likely to change due to environment
al factors such as light conditions, cloths, camera settings.
 In addition, people variability in terms of height, weigh and poses will
 make appearance much likely to vary.
 Due to this, some approaches try to get rid of these factors and detect
 pedestrians using only its motion information.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "cutler2000robust"

\end_inset

 detections are based on periodic motion analysis.
 The algorithm performs motion segmentation and tracking to later on compute
 the self-similarity between objects.
\end_layout

\begin_layout Itemize
Based on appearance + motion: Although the main used algorithms are based
 on appearance there are some such as 
\begin_inset CommandInset citation
LatexCommand cite
key "giebel2004bayesian,okuma2004boosted"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "giebel2004bayesian,okuma2004boosted"

\end_inset

 that will merge both appearance and motion in order to improve results.
 Most of these algorithms combine people detection and tracking, and so,
 they have been design to improve people tracking over video sequences.
\end_layout

\begin_layout Standard
In the table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Pedestrian-detection-performance"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "garcia2015people"

\end_inset

 propose some results from the State of the Art detectors depending on different
 datasets.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Pedestrian Detection Performance
\begin_inset CommandInset label
LatexCommand label
name "tab:Pedestrian-detection-performance"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
However, last years a new sort of detectors have start to be use detectors
 based on deep Convolutional Networks have improve notably the accuracy
 of all the previous algorithms.
 Examples such as ImageNet 
\begin_inset CommandInset citation
LatexCommand cite
key "krizhevsky2012imagenet"

\end_inset

 for image classification and Fast R-CNN 
\begin_inset CommandInset citation
LatexCommand cite
key "girshick2015fast"

\end_inset

 for object detection expose that deep convolutional networks outperform
 the previous mentioned algorithms.
\end_layout

\begin_layout Subsection
Object Proposals
\end_layout

\begin_layout Standard
Described detectors such as HOG, DPM or ACF utilized the well known 
\begin_inset Quotes eld
\end_inset

sliding window
\begin_inset Quotes erd
\end_inset

 algorithm, which means that an efficient classifier will test, in search
 of pedestrian, every possible image window.
 Parameters such as window size, or overlapping are common tuning values
 that will increase or decrease the performance of the detector.
 Those methods usually need from 
\begin_inset Formula $10^{4}$
\end_inset

 to 
\begin_inset Formula $10^{5}$
\end_inset

 windows per image and this number will grow exponentially for multi-scale
 detection.
 If the complexity of the core classifier is increased in every window testing,
 the computational time will end up being not affordable.
\end_layout

\begin_layout Standard
One of the most successful approach to overcame this time consumption problem
 without losing detection quality is by means of object proposals 
\begin_inset CommandInset citation
LatexCommand cite
key "hosang2016makes"

\end_inset

.
\end_layout

\begin_layout Standard
Object proposals will be such objects that could be fitted into the desired
 label classification.
 This object will be share common visual properties that will distinguish
 them from the background.
 If lower number of object proposals than sliding windows lead to a higher
 object recall, a speed-up will be achieve which means that more efforts
 can be focus on more sophisticated classifiers.
\end_layout

\begin_layout Standard
Both ImageNet and Fast R-CNN use detections proposals, which is one of the
 main reasons why they outperform previous algorithms.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "hosang2016makes"

\end_inset

 two set of proposal methods are analyzed:
\end_layout

\begin_layout Itemize
Grouping proposal methods.
 This methods attempt to generate multiple, and so, overlapping segment
 that are likely to correspond to objects.
 Usually this method generate region proposals by grouping super pixels,
 solving multiple graph cut problems, or directly using edge contours.
 One of the best examples for this methods is MCG 
\begin_inset CommandInset citation
LatexCommand cite
key "arbelaez2014multiscale"

\end_inset

.
\end_layout

\begin_layout Itemize
Window scoring proposal methods.
 An alternate approach is to score each candidate window according to the
 probability to contain an object.
 Best results for this methods are provided by EdgeBoxes 
\begin_inset CommandInset citation
LatexCommand cite
key "zitnick2014edge"

\end_inset

 which uses a coarse sliding window pattern which uses boundary estimation
 and a refinement step to improve performance.
\end_layout

\begin_layout Subsection
Research Directions
\end_layout

\begin_layout Standard
As said before this computer vision field is constantly in change and so
 some future work lines can be set.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "dollar2012pedestrian"

\end_inset

 some research directions are proposed that could be of interest in the
 scope of this work.
 
\end_layout

\begin_layout Enumerate
Context information should be added.
 Starting from the hypothesis that a person should be placed on the floor,
 the ground plane assumption can reduce errors if the detection for both
 the person and the floor are accurate.
 This could be achieve by extracting good contextual information from the
 scene which is one of the main objectives of the work.
\end_layout

\begin_layout Enumerate
Occlusion treatment.
 Usually pedestrians, due to other scene elements such as columns or even
 other pedestrians get occluded.
 When this happens performance degrades rapidly under even mild occlusion
 so, some improvements in this area will increase the performance in real
 life situations such as crowded spaces.
 
\end_layout

\begin_layout Subsection
Crowd Dynamics
\end_layout

\begin_layout Standard
Finally, there is many literature concerning pedestrian dynamics in the
 real world such as the Social Force Model (SFM) 
\begin_inset CommandInset citation
LatexCommand cite
key "mazzon2013multi"

\end_inset

 or people behavior in a built environment 
\begin_inset CommandInset citation
LatexCommand cite
key "turner2002encoding"

\end_inset

.
 The information coming from these algorithms will lead to predictions in
 people behavior and the paths they could follow which could help us to
 extract more accurate statistical data, refine people detections based
 on this previous behavior knowledge or even improve detection computational
 time searching pedestrian only in those paths they usually follow.
\end_layout

\begin_layout Section
Contextual Information
\end_layout

\begin_layout Standard
One can describe contextual information as the set of circumstances or facts
 that one can extract from a scene.
 Usually, this set of circumstances is a wealth of information that is not
 captured by the image but extracted by humans based on previously acquired
 knowledge.
 By taking a look to an outdoor image one can derive where the sky will
 be, what the weather conditions are, which time of the day...
 Also, by knowing the place the photo was taken, one can lead which objects
 will be more probable to appear in the scene.
\end_layout

\begin_layout Standard
When talking specifically about computer vision, contextual information
 will embrace for instance camera information (such as position, configuration,
 distance to an object, static or not), the set of objects that one could
 detect in the scene or how many views will be available...
\end_layout

\begin_layout Standard
All this set of information that is not extracted from the frame will provide
 a more general understanding about the scene and will help further algorithms.
\end_layout

\begin_layout Standard
If we now focus with the set of objects that one can observe from a scene,
 semantic segmentation techniques, which will be analyzed in the following
 section, aim to separate a scene into different observable objects.
\end_layout

\begin_layout Subsection
Semantic segmentation
\end_layout

\begin_layout Standard
Semantic information can often lead to low-level characteristics 
\begin_inset CommandInset citation
LatexCommand cite
key "manjunath2002introduction"

\end_inset

 such as global color or, on the other hand, it can describe an image by
 the position and status of relevant objects 
\begin_inset CommandInset citation
LatexCommand cite
key "oh2010content"

\end_inset

 such as cars according to its moving paths or, what is more important to
 our related work, concrete areas in a scene such as walls, corridors, walking
 paths...
 
\begin_inset CommandInset citation
LatexCommand cite
key "zhao2016pyramid"

\end_inset

.
\end_layout

\begin_layout Standard
In other words, semantic segmentation will have the goal to assign each
 pixel of an image a category label.
 If the prediction is accurate, it will provide complete semantic understanding
 from the scene (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Scene-parsing-on PSPNet"

\end_inset

) which means that one could have the position and label of some object.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Images/State Of the Art/PSPNet Image.png
	lyxscale 20
	width 50text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Scene parsing on ADE20K 
\begin_inset CommandInset citation
LatexCommand cite
key "zhou2016semantic"

\end_inset

.
 Image from 
\begin_inset CommandInset citation
LatexCommand cite
key "zhao2016pyramid"

\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "fig:Scene-parsing-on PSPNet"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
The main difficulty of scene parsing is related to the type of scene and
 by all means to the label variety that one can predict.
 
\begin_inset CommandInset citation
LatexCommand cite
key "zhao2016pyramid"

\end_inset

 has dealt with this problems by using deep Convolutional Neural Network
 and assigning relationships between different dataset labels, i.e.
 a an airplane is likely to be in runway or flying in the sky while not
 over a road.
 This relationships will reduce slightly the complexity of having large
 amounts of labels to predict.
\end_layout

\begin_layout Section
Multi-camera scenarios
\end_layout

\begin_layout Standard
The use of multi-camera is a common setup when dealing with video surveillance
 problems.
 Having multiple camera instances allows to observe the same event or object
 of interest from up to two different points of view.
 This will lead to a set of advantages in the scope of our work when dealing
 with pedestrian detection and semantic classification and also, some unavoidabl
e disadvantages.
\end_layout

\begin_layout Subsection
Advantages
\end_layout

\begin_layout Standard
As said in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Pedestrian-detection-and crowd patrons"

\end_inset

 one of the main research paths in pedestrian detection is the occlusion
 treatment.
 In this case, the use of a multi-camera scenario with computed homographies
 between camera frames will help to reproject detections from one camera
 to another whose miss rates are high so one could solve partially the problem
 of occlusions or at least improve the performance.
 
\end_layout

\begin_layout Standard
When talking about semantic segmentation the inclusion of a multi-camera
 system will arise some benefits.
 While a single-camera system could lead to misclassification of labels
 in the image or even to represent an object with many classes due to for
 example, camera capture problems, in a multi-camera system one camera instance
 could help to refine the classes in another one provided that, evidentially,
 they are analyzing the same common area.
\end_layout

\begin_layout Subsection
Disadvantages
\end_layout

\begin_layout Standard
The main disadvantage when dealing with multi-camera systems will be the
 exponential grow of computational time as algorithms should be performed
 
\begin_inset Formula $N$
\end_inset

 times being 
\begin_inset Formula $N$
\end_inset

 the number of camera instances.
 This issue could be solved by the use of some parallel coding that will
 perform cameras process separately.
\end_layout

\begin_layout Standard
Other disadvantages will be related with synchronization problems, as if
 the camera instances will be used to reproject objects/pedestrians from
 one camera to another they must evidentially represent the same exact moment
 in time, which depending on the setup will be more or less difficult.
\end_layout

\end_body
\end_document

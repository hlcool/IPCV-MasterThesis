#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass book
\begin_preamble


\AtBeginDocument{
  \def\labelitemii{\ding{71}}
  \def\labelitemiii{\ding{111}}
  \def\labelitemiv{\(\vartriangleright\)}
}



\usepackage{babel}
\addto\shorthandsspanish{\spanishdeactivate{~<>}}
\end_preamble
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding iso8859-15
\fontencoding T1
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing double
\use_hyperref true
\pdf_bookmarks false
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref section
\pdf_pdfusetitle false
\papersize a4paper
\use_geometry true
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1.5in
\topmargin 1.6in
\rightmargin 1.2in
\bottommargin 1.6in
\headheight 1.5in
\headsep 0.3in
\footskip 0.8in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle plain
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
State of the Art
\begin_inset CommandInset label
LatexCommand label
name "chap:State of the art"

\end_inset


\end_layout

\begin_layout Standard
As explained in Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "cha:Introduction"

\end_inset

, the analysis of a public crowed space embraces many different algorithms
 from Computer Vision disciplines.
 
\end_layout

\begin_layout Standard
This Chapter aims to study the State Of the Art in pedestrian detection
 approaches.
 In addition, it also covers the topic of contextual information and specificall
y, the algorithms in the field of semantic segmentation.
 The advantages and disadvantages of analysis in multi camera scenarios
 are also discussed.
\end_layout

\begin_layout Section
Pedestrian Detection
\begin_inset CommandInset label
LatexCommand label
name "sec:Pedestrian-detection"

\end_inset


\end_layout

\begin_layout Standard
Pedestrian detection (PD) has been a hot research topic in Computer Vision
 during the past few years due to its impact in several Computer Vision
 applications.
 Its main objective is to identify a potential object as a person by automatical
ly detecting its position and relative size in the scene.
\end_layout

\begin_layout Standard
Nowadays, it can be consider a partially-solved problem.
 Although there are excellent PD in the literature, there is no algorithm
 able to effectively perform PD on a generic scenario.
 This is the main reason why PD is still one of the most researched areas
 in computer vision.
\end_layout

\begin_layout Standard
The complexity related to PD lies on the large amount of available data-sets
 with different video and people characteristics including challenges such
 as: people occlusions, poses and scales and scenes captured under extreme
 illumination conditions.
 Caltech 
\begin_inset CommandInset citation
LatexCommand cite
key "dollar2009pedestrian"

\end_inset

 
\begin_inset Formula $-$
\end_inset

recorded on a vehicle in an urban environment
\begin_inset Formula $-$
\end_inset

, ETHZ 
\begin_inset CommandInset citation
LatexCommand cite
key "ess2007depth"

\end_inset

 
\begin_inset Formula $-$
\end_inset

recorded from a chariot which moves through pedestrian paths
\begin_inset Formula $-$
\end_inset

, TUD 
\begin_inset CommandInset citation
LatexCommand cite
key "wojek2009multi"

\end_inset

 
\begin_inset Formula $-$
\end_inset

static camera in a crossing campus scene
\begin_inset Formula $-$
\end_inset

 or INRIA 
\begin_inset CommandInset citation
LatexCommand cite
key "dalal2005histograms"

\end_inset

 
\begin_inset Formula $-$
\end_inset

collects precise people images both static and moving
\begin_inset Formula $-$
\end_inset

 are some of the PD data-sets that have been proposed through the years
 to train PD.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Image-summary-from datasets"

\end_inset

 gathers some examples of the images in these data-sets.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Images/State Of the Art/Caltech Dataset.jpg
	lyxscale 80
	width 40text%
	height 20theight%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Caltech 
\begin_inset CommandInset citation
LatexCommand cite
key "dollar2009pedestrian"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Images/State Of the Art/ETHZ Dataset.png
	lyxscale 30
	width 40text%
	height 20theight%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
ETHZ 
\begin_inset CommandInset citation
LatexCommand cite
key "ess2007depth"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Images/State Of the Art/TUD Campus Dataset.png
	lyxscale 30
	width 40text%
	height 20theight%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
TUD 
\begin_inset CommandInset citation
LatexCommand cite
key "wojek2009multi"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Images/State Of the Art/Inria Dataset.png
	lyxscale 20
	width 40text%
	height 20theight%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
INRIA 
\begin_inset CommandInset citation
LatexCommand cite
key "dalal2005histograms"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Examples images of PD data-sets
\begin_inset CommandInset label
LatexCommand label
name "fig:Image-summary-from datasets"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Classical Pedestrian Detection Approaches
\end_layout

\begin_layout Standard
Several PD in this State of the Art are arranged under three different topics.
 First, different pedestrian descriptor schemes are explained.
 Second, person detection approaches are studied.
 Finally, various approaches to define person model are analyzed.
\end_layout

\begin_layout Subsubsection*
Person Description 
\end_layout

\begin_layout Standard
An organization of existing PD approaches based on the descriptor may start
 with the Histograms of Oriented Gradients (HOG), which in combination with
 linear Support Vectors Machine (SVM) have been mainly used to describe
 pedestrian shape 
\begin_inset CommandInset citation
LatexCommand cite
key "dalal2005histograms"

\end_inset

.
 Differentially, discriminative Part Models (DPM) such as 
\begin_inset CommandInset citation
LatexCommand cite
key "felzenszwalb2008discriminatively"

\end_inset

 propose to divide the human body into different parts (head, trunk, legs...)
 and search for their combination on the image to extract PD.
\end_layout

\begin_layout Standard
Others PD approaches are based on the use of the Aggregate Channel Features
 
\begin_inset CommandInset citation
LatexCommand cite
key "dollar2014fast"

\end_inset

.
 Algorithms based on ACF rely on a combination of different channels such
 as normalized gradient magnitude, histogram of oriented gradients (6 channels),
 and LUV color channels to achieve the final detection.
\end_layout

\begin_layout Subsubsection*
Person Detection
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand cite
key "garcia2015people"

\end_inset

 object detection is defined as the extraction of potential object candidates
 to be a person from a scene.
 Mainly object detections algorithms are:
\end_layout

\begin_layout Itemize
Sliding window 
\begin_inset Formula $-$
\end_inset

also known as
\begin_inset Formula $-$
\end_inset

 exhaustive search: uses an efficient classifier to test every possible
 image window.
 Parameters such as window size, or overlapping between them, are common
 tuning values that increase or decrease the performance of the detector.
 These methods usually need from 
\begin_inset Formula $10^{4}$
\end_inset

 to 
\begin_inset Formula $10^{5}$
\end_inset

 windows per image to perform decently.
 This number grows exponentially for multi-scale detection.
 If the complexity of the core classifier is increased in every window testing,
 the computational time will end up being not affordable.
\end_layout

\begin_layout Itemize
Segmentation: Uses segmentation as a preliminary step for PD.
 The use of algorithms such as background subtraction lead to the segregation
 of the image.
 Alternatively, color segmentation based on color skin detection can be
 used to restrict people search.
 By all means, segmentation severally reduces person candidates reducing
 the computational time.
\end_layout

\begin_layout Itemize
Segmentation + Exhaustive search: Alternatively, a combination of previous
 techniques.
 In this case the previous step of segmentation does not lead to final candidate
s but to a delimited small area that could contain some candidates objects.
 After the segmentation process, a sliding window technique is performed
 over the reduced scene area.
 In this case, improvements from both approaches are exploited as the computatio
nal cost of the exhaustive search (which is its main drawback) is reduced
 by the use of segmentation.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Pedestrain-Detector-Example"

\end_inset

 depicts a flowchart for a generic PD approach which relies on the combination
 of segmentation and exhaustive search.
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Images/State Of the Art/Edge Pedestrian Detector Example.png
	lyxscale 20
	width 80text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Generic Pedestrian Detector Example Diagram.
\end_layout

\end_inset

Generic Pedestrian Detector Example Diagram.
 Image extracted from 
\begin_inset CommandInset citation
LatexCommand cite
key "garcia2015people"

\end_inset


\color red
 
\color inherit

\begin_inset CommandInset label
LatexCommand label
name "fig:Pedestrain-Detector-Example"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Subsubsection*
Person Model
\end_layout

\begin_layout Standard
The model of a person can be considered as the set of characteristics used
 to discriminate between people and any other object in the scene.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "garcia2015people"

\end_inset

 three different types of person model are assumed:
\end_layout

\begin_layout Itemize
Based on appearance: Most of the available detectors in the State of the
 Art use appearance information to define the person model.
 In this group one can differentiate two approaches to describe the shape
 of a person.
\end_layout

\begin_deeper
\begin_layout Itemize
Holistic: People are defined as a unique and indivisible region or shape.
\end_layout

\begin_layout Itemize
Part-based: Rely on more complex characteristics where a person is defined
 as a combination of multiple shapes, regions or parts of its body.
\end_layout

\begin_layout Standard
Examples of appearance-based detectors are those that use silhouettes to
 classify people, either from an holistic or a part-based basis, or color
 distribution.
\end_layout

\end_deeper
\begin_layout Itemize
Based on motion: Human appearance is likely to change due to environmental
 factors such as light conditions, clothes or camera settings.
 In addition, people variability in terms of height, weigh and poses make
 appearance likely to vary.
 For these reasons, some approaches try to get rid of these factors and
 detect pedestrians using only its motion information.
 For instance in 
\begin_inset CommandInset citation
LatexCommand cite
key "cutler2000robust"

\end_inset

, detections are based on a periodic motion analysis.
 
\end_layout

\begin_layout Itemize
Based on appearance + motion: Algorithms such as 
\begin_inset CommandInset citation
LatexCommand cite
key "giebel2004bayesian,okuma2004boosted"

\end_inset

 merge both appearance and motion information.
 Most of these algorithms combine people detection and tracking, targeting
 to improve people tracking rather than PD.
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand cite
key "garcia2015pdbm"

\end_inset

 a comparison of the performance of PD on different data-sets is made.
 This comparison is partially included in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Pedestrian-detection-performance"

\end_inset

.
 See 
\color blue

\begin_inset CommandInset href
LatexCommand href
name "VPU Website"
target "http://www-vpu.eps.uam.es/DS/PDbm/results.html"

\end_inset


\begin_inset Foot
status collapsed

\begin_layout Plain Layout

\color blue
http://www-vpu.eps.uam.es/DS/PDbm/results.html
\end_layout

\end_inset


\color inherit
 for the complete table.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
setlength
\backslash
extrarowheight{7pt}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="8">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Video
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
HOG
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ISM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Fusion
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Edge
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DTDP
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ACF
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Faster-RCNN
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
89.3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
71.4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
34.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
84.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
96.7
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
99.3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
99.7
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
69.2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
82.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
92.5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
90.2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
77.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
77.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
98.2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
55.6
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
75.7
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
64.3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
71.7
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
68.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
68.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
82.9
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5.4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
33.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
33.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
37.5
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Average AUC
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
56
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
57.5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
48
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
63
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
69.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
69.8
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
79.5
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Pedestrian Detection Performance
\end_layout

\end_inset

Pedestrian Detection Performance.
 Adapted from 
\begin_inset CommandInset citation
LatexCommand cite
key "garcia2015pdbm"

\end_inset

 (selected approaches).
 Metric for this evaluation is the average AUC.
 
\begin_inset CommandInset label
LatexCommand label
name "tab:Pedestrian-detection-performance"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Recent Trends in Pedestrian Detection
\end_layout

\begin_layout Standard
During this section recent PD trends in terms of person detection and descriptio
n are presented.
\end_layout

\begin_layout Subsubsection*
Person Detection
\begin_inset CommandInset label
LatexCommand label
name "subsec:Object-Proposals"

\end_inset


\end_layout

\begin_layout Standard
PD based on HOG, DPM and ACF generally rely on 
\begin_inset Quotes eld
\end_inset

sliding window
\begin_inset Quotes erd
\end_inset

 detectors , however, as mentioned before one of the main drawbacks of this
 approach is the high computational time needed to achieve good performance.
\end_layout

\begin_layout Standard
One of the most successful solutions to overcome this time consumption problem
 without losing detection quality is the use of object proposals 
\begin_inset CommandInset citation
LatexCommand cite
key "hosang2016makes"

\end_inset

.
\end_layout

\begin_layout Standard
Object proposals approaches perform a complete search over an image to detect
 potential object candidates.
 These candidates are detected as image areas with visual properties that
 distinguish them from the scene background.
\end_layout

\begin_layout Standard
In general, object proposal approaches reduce pedestrian candidates with
 respect to sliding-window like algorithms and generally outperform segmentation
 based methods.
 This advantages lead to a higher object recall and more efficient detection
 processes.
 Successful examples of using proposals to improve and speed-up detection
 include Faster R-CNN 
\begin_inset CommandInset citation
LatexCommand cite
key "ren2015faster"

\end_inset

.
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand cite
key "hosang2016makes"

\end_inset

 three set of proposal methods are analyzed:
\end_layout

\begin_layout Itemize

\series bold
Grouping proposal methods
\series default
 attempt to generate multiple, and so, overlapping segments that are likely
 to correspond to objects.
 Here one can distinguish between three types of methods according to how
 they generate proposals.
 Methods can generate proposals by groping super-pixels (SP), solving multiple
 graph cut (GC) problems or finally, using edge contours (EC).
 Among those that use SP we can find Selective Search 
\begin_inset CommandInset citation
LatexCommand cite
key "van2011segmentation"

\end_inset

, Randomized Prim's 
\begin_inset CommandInset citation
LatexCommand cite
key "manen2013prime"

\end_inset

, Rantalankia 
\begin_inset CommandInset citation
LatexCommand cite
key "rantalankila2014generating"

\end_inset

 or Chang 
\begin_inset CommandInset citation
LatexCommand cite
key "chang2011fusing"

\end_inset

.
 Those that use GC are CPMC 
\begin_inset CommandInset citation
LatexCommand cite
key "carreira2010constrained"

\end_inset

, Endres 
\begin_inset CommandInset citation
LatexCommand cite
key "endres2010category"

\end_inset

 or Rigor 
\begin_inset CommandInset citation
LatexCommand cite
key "humayun2014rigor"

\end_inset

.
 Finally Geodesic 
\begin_inset CommandInset citation
LatexCommand cite
key "krahenbuhl2014geodesic"

\end_inset

 and MCG 
\begin_inset CommandInset citation
LatexCommand cite
key "arbelaez2014multiscale"

\end_inset

 use EC to obtain proposals.
\end_layout

\begin_layout Itemize

\series bold
Window scoring proposal
\series default
 methods are an alternative approach to score each candidate window according
 to the probability to contain an object.
 Usually this methods tend to be faster and, in addition, they typically
 extract only bounding boxes.
 One can find among other approaches Objectness 
\begin_inset CommandInset citation
LatexCommand cite
key "alexe2010object"

\end_inset

, Rahtu 
\begin_inset CommandInset citation
LatexCommand cite
key "rahtu2011learning"

\end_inset

, Bing 
\begin_inset CommandInset citation
LatexCommand cite
key "cheng2014bing"

\end_inset

, EdgeBoxes 
\begin_inset CommandInset citation
LatexCommand cite
key "zitnick2014edge"

\end_inset

, Feng 
\begin_inset CommandInset citation
LatexCommand cite
key "feng2011salient"

\end_inset

, Zhang 
\begin_inset CommandInset citation
LatexCommand cite
key "zhang2011proposal"

\end_inset

, RandomizedSeeds 
\begin_inset CommandInset citation
LatexCommand cite
key "van2013online"

\end_inset

.
\end_layout

\begin_layout Itemize

\series bold
Alternative proposal methods
\series default
.
 Apart from the main groups a set of alternate approaches such as ShapeSharing
 
\begin_inset CommandInset citation
LatexCommand cite
key "kim2012shape"

\end_inset

 or Multi-box 
\begin_inset CommandInset citation
LatexCommand cite
key "erhan2014scalable"

\end_inset

 are also used to extract object proposals.
\end_layout

\begin_layout Subsubsection*
Person Description
\end_layout

\begin_layout Standard
In recent years new schemes of PD have been proposed.
 Detectors based on deep Convolutional Neural Networks (CNNs) have notably
 improved the accuracy of all the previous analyzed algorithms.
 
\end_layout

\begin_layout Standard
Examples such as ImageNet 
\begin_inset CommandInset citation
LatexCommand cite
key "krizhevsky2012imagenet"

\end_inset

 for image classification, CompACT 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/corr/CaiSV15"

\end_inset

, Fast-RCN 
\begin_inset CommandInset citation
LatexCommand cite
key "girshick2015fast"

\end_inset

 or Faster R-CNN 
\begin_inset CommandInset citation
LatexCommand cite
key "ren2015faster"

\end_inset

 for object detection expose that deep convolutional networks usually improve
 the performance of aforementioned approaches.
 This fact is clearly presented Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Pedestrian-detection-performance"

\end_inset

 where Faster R-CNN outperforms every other approach.
\end_layout

\begin_layout Subsection
Next Steps Towards Generic PD
\end_layout

\begin_layout Standard
PD is constantly in development and so, some future work lines can be set.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "dollar2012pedestrian"

\end_inset

 some research directions are proposed that could be of interest in the
 scope of this work.
 
\end_layout

\begin_layout Enumerate
Use of context information.
 Starting from the hypothesis that a person is standing on the floor, the
 ground plane assumption can reduce errors if the detection for both the
 person and the floor are accurate.
 This could be achieved by extracting useful contextual information from
 the scene.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "garcia2015people"

\end_inset

 contextual information is added to PD to increase performance.
 This is one of the main objectives of the work.
\end_layout

\begin_layout Enumerate
Occlusion treatment.
 Usually pedestrians, due to other scene elements such as columns or even
 other pedestrians appear occluded.
 When this happens PD performance is substantially degraded under even mild
 occlusions.
 Improvements in this area could increase the overall performance of PD
 in generic scenarios.
\end_layout

\begin_layout Section
Contextual Information
\end_layout

\begin_layout Standard
One can describe contextual information as the set of additional circumstances
 or facts that can be extracted from a scene besides the target of analysis.
 Generally, this set of circumstances is a source of information that is
 not extracted by machine applications but constitutes key evidences for
 humans, which acquired this knowledge during their life.
 By just taking a look to an outdoor image a human can derive where the
 sky will be, what the weather conditions are or which time of the day is.
 Also, by knowing the place where a video was recorded, one would imagine
 which objects are more or less probable to be in the scene.
\end_layout

\begin_layout Standard
Dealing with computer vision disciplines, contextual information sources
 also include camera information (such as position, configuration, distance
 to an object and camera motion), the set of objects that one could detect
 in the scene and the number of available cameras.
\end_layout

\begin_layout Standard
One can divide contextual information into two different levels: global
 and local .
 Besides, we can also divide contextual information into two different categorie
s: offline, and online.
 Finally, we focus on a set of specific methods to extract context 
\begin_inset Formula $-$
\end_inset

semantic segmentation
\begin_inset Formula $–$
\end_inset

.
\end_layout

\begin_layout Subsection
Global Context 
\end_layout

\begin_layout Standard
Global context considers descriptions from an image as a whole.
 For instance, if the context of a scene is known 
\begin_inset Formula $-$
\end_inset

kitchen
\begin_inset Formula $-$
\end_inset

, we can use this information to search for typical objects in this context
 
\begin_inset Formula $-$
\end_inset

e.g.
 a stove
\begin_inset Formula $-$
\end_inset

.
\end_layout

\begin_layout Standard
This kind of approaches are focused on psychology studies that suggests
 that human perceptual processes work following a hierarchically organized
 process 
\begin_inset CommandInset citation
LatexCommand cite
key "navon1977forest,rensink1997see"

\end_inset

.
 Our perception system goes from a global structure towards a more detailed
 analysis in a top-down scene interpretation.
\end_layout

\begin_layout Standard
Global context approaches aim to define a scene as an extra source of global
 information.
 The structure of a determinate scene image can be estimated by means of
 global image features as in 
\begin_inset CommandInset citation
LatexCommand cite
key "torralba2006contextual"

\end_inset

.
 
\end_layout

\begin_layout Subsection
Local Context
\end_layout

\begin_layout Standard
On the contrary, local context refers to contextual information related
 to a specific object, e.g.
 a kitchen table may help to predict the presence of a spoon.
 
\end_layout

\begin_layout Standard
The impact area of an object 
\begin_inset Formula $-$
\end_inset

in contextual terms
\begin_inset Formula $-$
\end_inset

 is defined as a set of neighboring objects, patches or even pixels.
 Algorithms dealing with the extraction of local contextual information
 aim to correctly define the area that surrounds an object to precisely
 detect other object instances.
 
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand cite
key "torralba2001detecting"

\end_inset

 the inclusion of local contextual regions such as facial bounding contour
 are used to improve face detection performance.
\end_layout

\begin_layout Subsection
Offline
\end_layout

\begin_layout Standard
Offline contextual information is defined as the set of circumstances that
 are computed before starting any kind of analysis procedure.
 This information leads to external image information that may be used to
 constraint analysis algorithms.
 Approaches such as 
\begin_inset CommandInset citation
LatexCommand cite
key "garcia2015people"

\end_inset

 use previously introduced contextual information to improve part-based
 PD over a scene.
\end_layout

\begin_layout Subsection
Online
\end_layout

\begin_layout Standard
Online information, on the other hand, is to be extracted with the analysis.
 Online extraction entails a degradation of an algorithm efficiency, albeit
 allows to dynamically update the context.
\end_layout

\begin_layout Standard
Examples of online (and local) contextual information extractors are the
 algorithms in the semantic segmentation branch.
 Next section (
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Semantic-Segmentation"

\end_inset

) discuss some of the approaches in this vein.
\end_layout

\begin_layout Subsection
Semantic Segmentation
\begin_inset CommandInset label
LatexCommand label
name "subsec:Semantic-Segmentation"

\end_inset


\end_layout

\begin_layout Standard
Semantic information is defined as the set of high-level elements from contextua
l information.
 This can often lead to characteristics such as global image color 
\begin_inset CommandInset citation
LatexCommand cite
key "manjunath2002introduction"

\end_inset

.
 It can also describe an image by the position and status of relevant objects
 
\begin_inset CommandInset citation
LatexCommand cite
key "oh2010content"

\end_inset

.
 Or it can also be used to define specific image areas in a scene such as
 walls, corridors or walking paths 
\begin_inset CommandInset citation
LatexCommand cite
key "zhao2016pyramid"

\end_inset

.
\end_layout

\begin_layout Standard
Semantic segmentation targets to assign each image pixel a high-level label.
 If accurately performed, it provides fully semantic understanding 
\begin_inset Formula $-$
\end_inset

which in terms of Computer Vision
\begin_inset Formula $-$
\end_inset

, means that the location of an object within an image is known.
 A potential result of a semantic segmentation method is depicted in Figure
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Scene-parsing-on PSPNet"

\end_inset

.
 In the Figure four different scenes are analyzed and divided into non-overlappi
ng semantic areas.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Images/State Of the Art/PSPNet Image.png
	lyxscale 20
	width 80text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Semantic segmentation on ADE20K data-set
\end_layout

\end_inset

Semantic segmentation on ADE20K data-set 
\begin_inset CommandInset citation
LatexCommand cite
key "zhou2016semantic"

\end_inset

 by the algorithm described in 
\begin_inset CommandInset citation
LatexCommand cite
key "zhao2016pyramid"

\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "fig:Scene-parsing-on PSPNet"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Semantic segmentation is a recent trend and nowadays, and so, it remains
 a significant challenge for the computer vision community.
 Due to its short-life term there is not yet a complete survey available
 in which algorithms are deeply analyzed and compared.
 However, there are a set of benchmark where developers can upload their
 obtained results with a given dataset and so, algorithms performance can
 be compared.
\end_layout

\begin_layout Standard
An example of a popular benchmark is the Cityscapes Data-set 
\begin_inset CommandInset citation
LatexCommand cite
key "cordts2016cityscapes"

\end_inset

.
 It is a large-scale data-set that contains stereo video sequences recorded
 in street scenes from among 50 different cities around the world.
 This data-set presents categories annotations over pixels in more than
 5000 frames.
 The set of categories is presented in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Cityscapes-Dataset-Class Definitions"

\end_inset

, whereas a subset of the compared methods in the 
\color blue

\begin_inset CommandInset href
LatexCommand href
name "Cityscapes Website"
target "https://www.cityscapes-dataset.com/"

\end_inset


\begin_inset Foot
status collapsed

\begin_layout Plain Layout

\color blue
https://www.cityscapes-dataset.com/
\end_layout

\end_inset


\color inherit
 are depict in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Cityscapes Dataset Challenge Results"

\end_inset

.
 Only those algorithms that have more than 80% on IoU class metric have
 been included in the Table.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
setlength
\backslash
extrarowheight{7pt}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="9" columns="2">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Category
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Classes
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Flat
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
road · sidewalk · parking · rail track
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Human
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
person · rider
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Vehicle
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
car · truck · bus · on rails · motorcycle · bicycle · caravan · trailer
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Construction
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
building · wall · fence · guard rail · bridge · tunnel
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Object
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
pole · pole group · traffic sign · traffic light
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Nature
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
vegetation · terrain
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Sky
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
sky
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Void
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ground · dynamic · static
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Cityscapes Data-set Class Definitions
\begin_inset CommandInset label
LatexCommand label
name "tab:Cityscapes-Dataset-Class Definitions"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
setlength
\backslash
extrarowheight{7pt}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Algorithm Name
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
IoU Category
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
IoU Class
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Available Code
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\color blue
\begin_inset CommandInset href
LatexCommand href
name "motovis"
target "http://www.motovis.com/"

\end_inset


\color inherit
(Anonymous)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
91.5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
81.3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
No
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
PSPNet 
\begin_inset CommandInset citation
LatexCommand cite
key "zhao2016pyramid"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
91.2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
81.2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Yes
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ResNet-38 
\begin_inset CommandInset citation
LatexCommand cite
key "wu2016wider"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
91.0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
80.6
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Yes
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
NetWarp (Anonymous)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
91.0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
80.5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
No
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
TuSimple_Coarse 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/corr/WangCYLHHC17"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
90.7
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
80.5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Yes
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Cityscapes Data-set Challenge Results
\end_layout

\end_inset

Cityscapes Data-set Challenge Results (Intersection over Union metric)
\begin_inset CommandInset label
LatexCommand label
name "tab:Cityscapes Dataset Challenge Results"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
PSPNet 
\begin_inset CommandInset citation
LatexCommand cite
key "zhao2016pyramid"

\end_inset

, ResNet-38 
\begin_inset CommandInset citation
LatexCommand cite
key "wu2016wider"

\end_inset

 and TuSimple_Coarse 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/corr/WangCYLHHC17"

\end_inset

 are all based on convolutional networks.
 This fact reveals that deep convolutional neural networks have led to significa
nt improvement over previous semantic segmentation systems since the presentatio
n of AlexNet 
\begin_inset CommandInset citation
LatexCommand cite
key "krizhevsky2012imagenet"

\end_inset

 in 2012.
\end_layout

\begin_layout Standard
However, even when using CNNs, the main difficulty of scene parsing is related
 to the type of scene and to label variety.
 
\end_layout

\begin_layout Standard
TuSimple_Coarse 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/corr/WangCYLHHC17"

\end_inset

 propose a combination between dense upsampling convolution (DUC) to generate
 pixel-level prediction and a hybrid dilated convolution (HDC) framework.
\end_layout

\begin_layout Standard
ResNet-38 
\begin_inset CommandInset citation
LatexCommand cite
key "wu2016wider"

\end_inset

 on the other hand, propose not only to not increase CNNs depth, but rather
 to ensemble many relatively shallow networks to increase performance.
 Their approach also improves usability reducing memory use and sometimes
 even training time.
 
\end_layout

\begin_layout Standard
Finally, PSPNet 
\begin_inset CommandInset citation
LatexCommand cite
key "zhao2016pyramid"

\end_inset

 deals with this problems assigning relationships between different labels,
 i.e.
 an airplane is likely to be in runway or flying in the sky while not over
 a road or in the water.
 This relationships reduce slightly the complexity of having large amounts
 of labels to predict and improve the general performance of the algorithm.
 
\end_layout

\begin_layout Standard
In Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Semantic-Segmentation-results"

\end_inset

 some visual examples of how this algorithms perform on Cityscapes Data-set
 frames are displayed.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Images/State Of the Art/ResNet-38 Results.png
	lyxscale 30
	width 90text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
ResNet-38 Algorithm.
 From top to bottom: Input images, ground truth and results.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Images/State Of the Art/PSPNet Results.png
	lyxscale 30
	width 90text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
PSPNet Algorithm.
 From left to right: Input images, ground truth and results.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Images/State Of the Art/TuSimple_Coarse Results.png
	lyxscale 30
	width 90text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
TuSimple_Coarse Algorithm.
 From left to right: Input images, ground truth and results.
\begin_inset CommandInset label
LatexCommand label
name "fig:PSPNet-Algorithm-1"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Semantic Segmentation result examples on Cityscapes Data-set 
\begin_inset CommandInset label
LatexCommand label
name "fig:Semantic-Segmentation-results"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Multi-camera scenarios
\end_layout

\begin_layout Standard
The use of multiple cameras is a common setup when dealing with video surveillan
ce problems.
 One can define a multi-camera scenario as a space that has more than one
 video camera recording.
 Ideally, the recordings for the different cameras are temporally aligned
 
\begin_inset Formula $-$
\end_inset

synchronized
\begin_inset Formula $-$
\end_inset

.
 Having 
\begin_inset Formula $N$
\end_inset

 camera instances allows to observe the same event or object of interest
 from different points of view.
 This leads to a set of advantages in the scope of our work when dealing
 with PD and semantic classification and also, to some unavoidable disadvantages.
\end_layout

\begin_layout Itemize
Advantages
\end_layout

\begin_deeper
\begin_layout Standard
As discussed in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Pedestrian-detection"

\end_inset

 one of the research paths towards PD is generic occlusion handling.
 In this case, the use of a multi-camera scenario with relating camera views
 could help.
 This could be achieved by reprojecting detections from one camera to another
 whose miss rates are high as in 
\begin_inset CommandInset citation
LatexCommand cite
key "miguelez2016Deteccion"

\end_inset

.
 
\end_layout

\begin_layout Standard
When dealing with semantic segmentation, the inclusion of a multi-camera
 system may arise some benefits.
 A single-camera system could lead to misclassification of labels in the
 image.
 In a multi-camera system one camera instance may help to refine the classes
 in another one provided that, evidentially, the views of both cameras partially
 overlap 
\begin_inset CommandInset citation
LatexCommand cite
key "xiao2009multiple"

\end_inset

.
\end_layout

\end_deeper
\begin_layout Itemize
Disadvantages
\end_layout

\begin_deeper
\begin_layout Standard
The main disadvantage when dealing with multi-camera systems is the exponential
 grow of computational time.
 Algorithms should be performed 
\begin_inset Formula $N$
\end_inset

 times.
 This issue could be solved by the use of parallel coding to process cameras
 views simultaneously.
\end_layout

\begin_layout Standard
Besides, the use of multiple cameras entail two additional tasks: the temporal
 alignment of the views 
\begin_inset Formula $-$
\end_inset

synchronization
\begin_inset Formula $-$
\end_inset

 and the spatial arrangement of the different views 
\begin_inset Formula $-$
\end_inset

homographies
\begin_inset Formula $-$
\end_inset

.
\end_layout

\end_deeper
\end_body
\end_document
